getch
rich
llama-cpp-python